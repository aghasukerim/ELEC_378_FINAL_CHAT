{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ElaQqihjlPW3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchaudio\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialize Dataset"
      ],
      "metadata": {
        "id": "lqtQcVq9HS20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#800 audio samples in training, will split into 640 for train, 160 for validation. 200 test data\n",
        "\n",
        "annotations = '/content/drive/MyDrive/elec378/final_project_data/train.csv' #directory that annotation file is in\n",
        "train_data = '/content/drive/MyDrive/elec378/final_project_data/train/' #directory that train data are in\n",
        "test_data = '/content/drive/MyDrive/elec378/final_project_data/test/' #directory that test data are in\n",
        "\n",
        "audio_directory = '/content/drive/MyDrive/elec378/final_project_data/train/'\n",
        "#extract sampling rate\n",
        "dummy, sr = librosa.load('/content/drive/MyDrive/elec378/final_project_data/train/train333.wav')"
      ],
      "metadata": {
        "id": "BwNs05nbqB0c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=sr,\n",
        "        n_fft=1024,\n",
        "        hop_length=512,\n",
        "        n_mels=64\n",
        "    )\n",
        "\n",
        "queef = mel_spectrogram(torch.from_numpy(dummy))\n",
        "sliced_queef = queef[:,:1293]\n",
        "print(queef.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edVAM21Xk_NK",
        "outputId": "5dfd7fd3-5e2f-4ce2-8999-6dd1b3d35d1e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1293])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xy = pd.read_csv(annotations)\n",
        "\n",
        "filenames = xy['ID']\n",
        "labels = xy['Genre']\n",
        "print(filenames[0])\n",
        "bong = \"bongo\"\n",
        "print(f'/content/drive/MyDrive/elec378/final_project_data/train/{bong}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhXFS-ZTtAZ1",
        "outputId": "e4b72103-69f8-4c15-e48a-24ac3c2329b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train000.wav\n",
            "/content/drive/MyDrive/elec378/final_project_data/train/bongo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xy.iloc[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cqi7GZTCCc0q",
        "outputId": "44dfa79f-dbb7-471a-c550-d62bc7f7de05"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pop'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainDataset(Dataset): #dataset class to create dataloader object\n",
        "  def __init__(self,audio_dir,transformation):\n",
        "    self.annotations = xy\n",
        "    self.audio_dir = audio_dir\n",
        "    self.transformation = transformation\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    audio_sample_path = self._get_audio_sample_path(index)\n",
        "    label = self._get_audio_sample_label(index)\n",
        "    signal, sr = torchaudio.load(audio_sample_path)\n",
        "    signal = self._chop_down_(signal)\n",
        "    signal = self.transformation(signal)\n",
        "    print('the label is:', type(label))\n",
        "    return signal, label\n",
        "\n",
        "  def _get_audio_sample_label(self,index):\n",
        "    return self.annotations.iloc[index,1]\n",
        "\n",
        "  def _chop_down_(self, signal):\n",
        "    return signal[:,:1293] #max length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "\n",
        "  def _get_audio_sample_path(self,index):\n",
        "    return f'/content/drive/MyDrive/elec378/final_project_data/train/{filenames[index]}'\n"
      ],
      "metadata": {
        "id": "p05OYo-43h_h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Net"
      ],
      "metadata": {
        "id": "LtgQZ6xIha9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code and architecture partially from musikalkemist on github, modified to fit our data. Inspired by CNN videos by far1din\n",
        "#I want final layer with 128 features\n",
        "class MGenreCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 1, #mel spectrograms are in grayscale\n",
        "            out_channels = 16, #number of convolutional filters (\"features learned\")\n",
        "            kernel_size = 3, #3x3 filter for every convolution\n",
        "            stride = 1, #step size\n",
        "            padding = 2 #prevents the data's dimensionality from decreasing\n",
        "        ),\n",
        "        nn.ReLU(), #activation function\n",
        "\n",
        "        #get maximum out of the result mtx of convolution layer depending on kernel size (pooling)\n",
        "        nn.MaxPool2d(kernel_size=2) #2x2 window for each pooling\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 16, #output of conv1\n",
        "            out_channels = 32, #double input\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            padding = 2\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 32, #output of conv2\n",
        "            out_channels = 64, #double input\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            padding = 2\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv4 = nn.Sequential(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 64, #output of conv3\n",
        "            out_channels = 128, #double input\n",
        "            kernel_size = 3,\n",
        "            stride = 1,\n",
        "            padding = 2\n",
        "        ),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear = nn.Linear(128 * 5 * 4, 10)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,input_data):\n",
        "    x = self.conv1(input_data)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear(x)\n",
        "    predictions = self.softmax(logits)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "bOL4xW67hc_g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Pipeline"
      ],
      "metadata": {
        "id": "-E3ph-nESb1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_epoch(model, data_loader, loss_fn, optimiser, device):\n",
        "    for input, target in data_loader:\n",
        "        print('input: ', type(input))\n",
        "        print('target: ', type(target))\n",
        "        input = input.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # calculate loss\n",
        "        prediction = model(input)\n",
        "        loss = loss_fn(prediction, target)\n",
        "\n",
        "        # backpropagate error and update weights\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "    print(f\"loss: {loss.item()}\")\n",
        "\n",
        "\n",
        "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
        "    for i in range(epochs):\n",
        "        print(f\"Epoch {i+1}\")\n",
        "        train_single_epoch(model, data_loader, loss_fn, optimiser, device)\n",
        "        print(\"---------------------------\")\n",
        "    print(\"Finished training\")\n"
      ],
      "metadata": {
        "id": "9F6qQvGklm9d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 10 #plot loss function over time to check for overfitting\n",
        "learning_rate = 0.001 #lambda/alpha value\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "  else:\n",
        "    device = \"cpu\"\n",
        "  print(f\"Using {device}\")\n",
        "\n",
        "  mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "        sample_rate=sr,\n",
        "        n_fft=1024,\n",
        "        hop_length=512,\n",
        "        n_mels=64\n",
        "    )\n",
        "\n",
        "  training_set = TrainDataset(train_data, mel_spectrogram)\n",
        "  data_loader = DataLoader(training_set, batch_size=batch_size)\n",
        "\n",
        "  model = MGenreCNN().to(device)\n",
        "  print(model)\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  optimiser = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "  train(model, data_loader, loss_fn, optimiser, device, epochs)\n",
        "\n",
        "  torch.save(model.state_dict(), \"genrenet.py\")"
      ],
      "metadata": {
        "id": "HsEAOnw5SapX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79cdeb89-702f-480c-a03b-3aa83db76dd6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu\n",
            "MGenreCNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear): Linear(in_features=2560, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "Epoch 1\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "the label is: <class 'str'>\n",
            "input:  <class 'torch.Tensor'>\n",
            "target:  <class 'tuple'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'to'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0fa46753f4eb>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"genrenet.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6b8bde388eee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, loss_fn, optimiser, device, epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {i+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain_single_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Finished training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6b8bde388eee>\u001b[0m in \u001b[0;36mtrain_single_epoch\u001b[0;34m(model, data_loader, loss_fn, optimiser, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'target: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
          ]
        }
      ]
    }
  ]
}